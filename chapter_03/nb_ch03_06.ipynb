{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2sP8Kwe7L9Z"
   },
   "source": [
    "\n",
    "## Fitting a linear regression model with TF Eager\n",
    "\n",
    "**Goal:** In this notebook you will see how to use TF Eager to fit the parameters (slope and intercept) of a simple linear regression model via gradient descent (GD). \n",
    "\n",
    "**Usage:** The idea of the notebook is that you try to understand the provided code by running it, checking the output and playing with it by slightly changing the code and rerunning it. \n",
    "\n",
    "**Dataset:** You work again with the systolic blood pressure and age data of 33 American women, which is generated and visualized in the upper part of the notebook.\n",
    "\n",
    "**Content:**\n",
    "\n",
    "* fit a linear model via the sklearn machine learning library of python to get the fitted values of the intercept and slope as reference. \n",
    "\n",
    "* use the tensorflow library and enable the tf eager mode to fit the parameters of the simple linear model via GD with the objective to minimize the MSE loss. \n",
    "    * define the mse loss function \n",
    "    * apply the gradients_function of tf eager on the loss w.r.t. the parameters\n",
    "    * use the gradients to update the parameter values via update formula\n",
    "    * iterate over the two former steps for many steps and check the current values of the estimated model parameters and the loss after each updatestep \n",
    "    * verify that the estimated parameter values converge to the values which you got from the sklearn fit.  \n",
    "\n",
    "\n",
    "[open in colab](https://colab.research.google.com/github/tensorchiefs/dl_book/blob/master/chapter_03/nb_ch03_06.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install tensorflow 2.0 to run this notebook\n",
      "Tensorflow version:  1.14.0  running in colab?:  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try: #If running in colab \n",
    "    import google.colab\n",
    "    IN_COLAB = True \n",
    "except:\n",
    "    IN_COLAB = False\n",
    "if (not tf.__version__.startswith('2')): #Checking if tf 2.0 is installed\n",
    "    if IN_COLAB: #If running in colab install tf 2.0\n",
    "        !pip install tensorflow==2.0.0-alpha0  \n",
    "    print('Please install tensorflow 2.0 to run this notebook')\n",
    "print('Tensorflow version: ',tf.__version__, ' running in colab?: ', IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMlU4PJJ5QO7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3c9bh7zMVhP"
   },
   "source": [
    "Here we read in the systolic blood pressure and the age of the 33 American women in our dataset. Then we use the sklearn library to find the optimal values for the slope a and the intercept b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvINwW1vydo9"
   },
   "outputs": [],
   "source": [
    "# Blood Pressure data\n",
    "x = [22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58,  9, \n",
    "     49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81]\n",
    "y = [131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114, \n",
    "     115, 153, 123, 133, 157, 117, 128, 155, 122, 183,\n",
    "     176,  99, 130, 172, 121, 133, 178, 147, 144, 217] \n",
    "x = np.asarray(x, np.float32) \n",
    "y = np.asarray(y, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "OurbybEoydpB",
    "outputId": "2887d477-074a-47d1-9e50-65a5b483b997"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept =  87.67143 solpe =  1.1050216\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(x=x,y=y)\n",
    "plt.title(\"blood pressure vs age\")\n",
    "plt.xlabel(\"x (age)\")\n",
    "plt.ylabel(\"y (sbp)\")\n",
    "\n",
    "model = LinearRegression()\n",
    "res = model.fit(x.reshape((len(x),1)), y)\n",
    "predictions = model.predict(x.reshape((len(x),1)))\n",
    "plt.plot(x, predictions)\n",
    "plt.show()\n",
    "print(\"intercept = \",res.intercept_,\"solpe = \", res.coef_[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxlyNp9uSKYd"
   },
   "source": [
    "## TF Eager\n",
    "\n",
    "Now we want to use the TF Eager mode to find the optimal parameters for the linear regression problem. First we define our mse loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQI88BUK_FN0"
   },
   "outputs": [],
   "source": [
    "def loss(a, b):\n",
    "  y_hat = a*x + b\n",
    "  return tf.reduce_mean((y_hat - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzQzM4Kq56Ai"
   },
   "source": [
    "We can do a forwad pass and can calculate the loss (mse) with the initial values a=0 and b=139 (139 is the mean of the blood pressure and slope a=0 implies that the model predicts the mean for each age). Note that `a` and `b` must be `tf.Variables`. We see the loss value in the numpy argument in the output. In contrast to old (pre 2.0) TensorFlow we don't need to run a session to get loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "nYbreWHHcX0e",
    "outputId": "62d2fac4-a285-4f81-a742-2a48c9d71b25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(139.0)\n",
    "loss(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4gDPW676omn"
   },
   "source": [
    "Now we define that we want to have the gradients of the loss w.r.t to our two model parameters, the slope `a` and the intercept `b`. In the next cell we print the gradient of the loss w.r.t `a` and gradient of the loss w.r.t to `b`. Note that we calculated the loss for all data points and therefore we get different gradients compared to nb_04, where we only used one datapoint. To be able to calculate the gradient of the loss, we must store the itermediate values needed for calculating the gradients in an object called tape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "I am running same tensorflow as you... perhaps difference in our environment and since i am using my own docker image, that's might be the reason. Please check on your end.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VC0mP77EFwWX",
    "outputId": "83e7d2f7-383b-4526-ff58-2385e8ec6b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at  Tensor(\"Mean_2:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RefVariable' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-24f2d5cf1b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss at \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mgrad_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RefVariable' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(139.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  loss_val = loss(a,b)\n",
    "  print(\"Loss at \", loss_val)\n",
    "  grad_a, grad_b = tape.gradient(loss_val, [a,b])\n",
    "  print(grad_a, grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3u3ksK39s70"
   },
   "source": [
    "Now, let's use gradient descent to opimize the slope a and the intercept b. The start values are a=0 and b=139, our learning rate eta is 0.0004 and we do 80000 updatesteps with all 33 observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "HCasZHdLWmG9",
    "outputId": "ce82424d-0904-45c8-bdb0-850f06d8f8b9"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RefVariable' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-208a03d10b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrad_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RefVariable' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "a  = tf.Variable(0.0)\n",
    "b = tf.Variable(139.0)\n",
    "eta = 0.0004\n",
    "for i in range(80000):\n",
    "  with tf.GradientTape() as tape: #Record the gradients from now on\n",
    "    y_hat = a*x + b\n",
    "    loss = tf.reduce_mean((y_hat - y)**2)   \n",
    "    grad_a, grad_b  = tape.gradient(loss, [a,b])\n",
    "    a = tf.Variable(a - eta * grad_a)\n",
    "    b = tf.Variable(b - eta * grad_b)\n",
    "\n",
    "    if (i % 5000 == 0):\n",
    "      print(\"Epoch:\",i, \"slope=\",a.numpy(),\"intercept=\",b.numpy(),\"gradient_a\", grad_a.numpy(), \"gradient_b\",grad_b.numpy(), \"mse=\", loss.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kt9XXxcH8d3k"
   },
   "source": [
    "Let's look at the final values for the slope a,the intercept b and the mse loss. We know form the closed formula solution that:\n",
    "\n",
    "1.   optimal value for a: 1.1050216\n",
    "2.   optimal value for b: 87.67143\n",
    "3.   minimal loss: 349.200787168560\n",
    "\n",
    "After 80000 update steps we are very close to the optimal values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "y_46N75AEbuM",
    "outputId": "48c140f0-1704-402e-ed20-9ecd203924c6"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RefVariable' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-92f78b10a3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RefVariable' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "print(a.numpy(), b.numpy(), loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nb_06.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
